# ğŸ“± InvisInk Android App

Complete Android application implementation of the InvisInk air-drawing calculator.

## ğŸ“ Project Structure

```
android_app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”‚   â”œâ”€â”€ java/com/invisink/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MainActivity.kt          # Main activity
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ HandTracker.kt           # MediaPipe hand tracking
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SymbolClassifier.kt     # TensorFlow Lite inference
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ DrawingCanvas.kt         # Custom drawing view
â”‚   â”‚   â”‚   â”œâ”€â”€ res/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ layout/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ activity_main.xml    # Main UI layout
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ values/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ strings.xml
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ colors.xml
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ themes.xml
â”‚   â”‚   â”‚   â””â”€â”€ AndroidManifest.xml
â”‚   â”‚   â””â”€â”€ assets/                          # Put model files here
â”‚   â”‚       â”œâ”€â”€ invisink_model.tflite         # Your converted model
â”‚   â”‚       â””â”€â”€ hand_landmarker.task          # MediaPipe model
â”‚   â””â”€â”€ build.gradle.kts
â”œâ”€â”€ build.gradle.kts
â”œâ”€â”€ settings.gradle.kts
â””â”€â”€ gradle.properties
```

## ğŸš€ Setup Instructions

### Step 1: Convert Your Model

First, convert your Keras model to TensorFlow Lite:

```bash
python convert_model_to_tflite.py
```

This creates `invisink_model.tflite` - copy it to `android_app/app/src/main/assets/`

### Step 2: Download MediaPipe Hand Landmarker Model

1. Visit: https://developers.google.com/mediapipe/solutions/vision/hand_landmarker
2. Download: `hand_landmarker.task`
3. Place in: `android_app/app/src/main/assets/`

### Step 3: Open in Android Studio

1. Open Android Studio
2. File â†’ Open â†’ Select `android_app` folder
3. Let Gradle sync (this may take a few minutes)

### Step 4: Build and Run

1. Connect an Android device or start an emulator
2. Click Run (â–¶ï¸) or press Shift+F10
3. Grant camera permission when prompted

## ğŸ“‹ Requirements

- **Android Studio**: Latest version (Hedgehog or newer)
- **Min SDK**: 24 (Android 7.0)
- **Target SDK**: 34 (Android 14)
- **Kotlin**: 1.9.20+
- **Gradle**: 8.2+

## ğŸ”§ Key Features

### MainActivity.kt
- Camera setup using CameraX
- Hand tracking integration
- Gesture recognition logic (matches Python app)
- Symbol classification
- Expression solving

### HandTracker.kt
- MediaPipe hand landmark detection
- Gesture recognition (FINGERTIP, FIST, THUMBS_UP, OPEN_HAND)
- Real-time hand tracking

### SymbolClassifier.kt
- TensorFlow Lite model loading
- Image preprocessing (30x30 grayscale)
- Symbol classification (16 classes)

### DrawingCanvas.kt
- Custom view for drawing fingertip path
- Overlay on camera preview
- Symbol bitmap extraction

## ğŸ® Gesture Controls

- **ğŸ‘† Index Finger Extended**: Draw symbols in the air
- **âœŠ Closed Fist**: Recognize the drawn symbol (wait 1.5s between recognitions)
- **ğŸ‘ Thumbs Up**: Solve the equation and display result
- **âœ‹ Open Hand**: Clear the canvas and reset

## ğŸ“ Notes

1. **Model File**: Ensure `invisink_model.tflite` is in `app/src/main/assets/`
2. **MediaPipe Model**: Ensure `hand_landmarker.task` is in `app/src/main/assets/`
3. **Permissions**: Camera permission is requested at runtime
4. **Performance**: Uses GPU acceleration for MediaPipe (if available)

## ğŸ› Troubleshooting

### Model Not Found
- Ensure `invisink_model.tflite` exists in `app/src/main/assets/`
- Check file name matches exactly

### Hand Not Detected
- Ensure good lighting
- Position hand 2-3 feet from camera
- Show palm clearly to camera

### Build Errors
- Sync Gradle: File â†’ Sync Project with Gradle Files
- Clean project: Build â†’ Clean Project
- Invalidate caches: File â†’ Invalidate Caches

## ğŸ“š Dependencies

- **CameraX**: Camera API
- **MediaPipe Tasks Vision**: Hand tracking
- **TensorFlow Lite**: Model inference
- **Kotlin Coroutines**: Async operations

## ğŸ”„ Matching Python App Logic

This Android app mirrors the functionality of `invisink_app.py`:

- âœ… Same gesture recognition logic
- âœ… Same symbol classification (16 classes)
- âœ… Same debounce timing (1.5 seconds)
- âœ… Same expression solving
- âœ… Same UI feedback

## ğŸ“± Testing

Test on a real device for best results:
- Camera access works better on real devices
- Performance is more accurate
- Gesture recognition is more reliable

## ğŸš€ Next Steps

1. Convert your model: `python convert_model_to_tflite.py`
2. Copy model to assets folder
3. Download MediaPipe model
4. Open in Android Studio
5. Build and run!

---

**Ready to build your Android app!** ğŸ‰

